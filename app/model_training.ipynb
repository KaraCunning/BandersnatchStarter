{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from data import Database\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_URL: mongodb+srv://kara_labs1:Labssprint1@cluster0.4mwhcea.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\n"
     ]
    }
   ],
   "source": [
    "print(\"DB_URL:\", os.getenv(\"DB_URL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"app\"))\n",
    "\n",
    "from data import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on sample size: 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>energy</th>\n",
       "      <th>rarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>Rank2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>Rank1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>63</td>\n",
       "      <td>Rank2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>Rank1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>23</td>\n",
       "      <td>Rank2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   health  energy rarity\n",
       "0      52      28  Rank2\n",
       "1      46      33  Rank1\n",
       "2      42      63  Rank2\n",
       "3      27      21  Rank1\n",
       "4      65      23  Rank2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = Database()\n",
    "monsters = list(db.collection.find())\n",
    "df = pd.DataFrame(monsters)\n",
    "\n",
    "#drop Mongo_id as it is not useful in this model training\n",
    "df = df.drop(columns=[\"_id\"])\n",
    "\n",
    "df = df.head(1000)\n",
    "\n",
    "print(\"Training on sample size:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   health  energy rarity\n",
       " 0      52      28  Rank2\n",
       " 1      46      33  Rank1\n",
       " 2      42      63  Rank2\n",
       " 3      27      21  Rank1\n",
       " 4      65      23  Rank2,\n",
       " (800, 2),\n",
       " (200, 2))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#separate featrues(x) and target(y)\n",
    "X = df[[\"health\", \"energy\"]]\n",
    "y = df[\"rarity\"]\n",
    "\n",
    "#encode target labels (Rank1, Rank2, etc.)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "#scale feature\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "df.head(), X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize models\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/RandomForest Accuracy: 0.230\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.35      0.31        52\n",
      "           1       0.15      0.10      0.12        50\n",
      "           2       0.25      0.34      0.29        44\n",
      "           3       0.19      0.15      0.17        54\n",
      "\n",
      "    accuracy                           0.23       200\n",
      "   macro avg       0.22      0.23      0.22       200\n",
      "weighted avg       0.22      0.23      0.22       200\n",
      "\n",
      "\n",
      "/LogisticRegression Accuracy: 0.210\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.04      0.06        52\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.22      0.91      0.35        44\n",
      "           3       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.21       200\n",
      "   macro avg       0.09      0.24      0.10       200\n",
      "weighted avg       0.09      0.21      0.09       200\n",
      "\n",
      "\n",
      "/XGBoost Accuracy: 0.225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.33      0.28        52\n",
      "           1       0.19      0.10      0.13        50\n",
      "           2       0.21      0.27      0.24        44\n",
      "           3       0.24      0.20      0.22        54\n",
      "\n",
      "    accuracy                           0.23       200\n",
      "   macro avg       0.22      0.23      0.22       200\n",
      "weighted avg       0.22      0.23      0.22       200\n",
      "\n",
      "\n",
      " Best model: RandomForest with accuracy0.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karacunningham/Desktop/labs_sprint1/BandersnatchStarter/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/karacunningham/Desktop/labs_sprint1/BandersnatchStarter/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/karacunningham/Desktop/labs_sprint1/BandersnatchStarter/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    #train\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #predict model\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    #evaluate\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n/{name} Accuracy: {acc:.3f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    results[name] = acc\n",
    "\n",
    "best_model = max(results, key=results.get)\n",
    "print(f\"\\n Best model: {best_model} with accuracy{results[best_model]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model summary. After training and evaluating 3 models, RandomForestClassifier, LogisticRegression and XGBoostClassifier, on a 1000 monster dataset the best model was the RandomForestClassifier model with the accuracy of 23%. The dataset has four rarity classes (Rank1-4) and the features (health and energy). It is difficult for the models to separate the features clearly because they overlap across the classes.\n",
    "\n",
    "LogisticRegression performed poorly due to the overlapping features. It assumed a linear relationship to the features and the target. This misclassified most of the monsters creating a low precision and recall for many. Some weren't predicted at all with a recall of 0.\n",
    "\n",
    "XGBoostClassifier performed a bit better than the LogisticRegression model but not by much. The XGBoostClassifier uses gradient boost to correct errors from previous predictions which would have helped a bit with the captureing some of the non-linear relationships that the LogisticRegression didn't. The XGBoostClassification model's gradiant boost feature was not significant to out perform the RandomForestClassifier due to the small dataset.\n",
    "\n",
    "RandomForestClassifier created a non-linear relationship between the features and target which allowed for a better balanced predictions. This makes the RandomForestClassifier a more reliable predictions model for this dataset. Therefore; the RandomForestClassifier is the model of choice to continue training and evaluating the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
